{"updated_at": "2012-03-04T17:37:28Z", "repo": "rails", "created_at": "2012-03-04T17:37:28Z", "owner": "rails", "url": "https://api.github.com/repos/rails/rails/issues/comments/4311441", "id": 4311441, "issue_url": "https://api.github.com/repos/rails/rails/issues/5263", "issue_id": 5263, "user": {"repos_url": "https://api.github.com/users/jch/repos", "type": "User", "html_url": "https://github.com/jch", "starred_url": "https://api.github.com/users/jch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jch/subscriptions", "following_url": "https://api.github.com/users/jch/following{/other_user}", "gravatar_id": "acd4b5803e806bf0ed70299f15cd6d18", "organizations_url": "https://api.github.com/users/jch/orgs", "url": "https://api.github.com/users/jch", "gists_url": "https://api.github.com/users/jch/gists{/gist_id}", "avatar_url": "https://1.gravatar.com/avatar/acd4b5803e806bf0ed70299f15cd6d18?d=https%3A%2F%2Fidenticons.github.com%2Fa1af768d3b16885b8eb893d58712c1ea.png", "id": 19874, "events_url": "https://api.github.com/users/jch/events{/privacy}", "login": "jch", "received_events_url": "https://api.github.com/users/jch/received_events", "followers_url": "https://api.github.com/users/jch/followers"}, "body": "@jeremy Thanks! I agree with your point of using the lowest latency cache first, but the reason for putting memcache before memory in our application is because we wanted the app instances to share the cache as much as possible. The memory store serves as a fallback in case memcache is temporarily unavailable and buys us time to bring memcache back online.\r\n\r\nOptions for the underlying cache stores can be specified, so the alternate setup for lower latency access with a bounded first-tier cache could look like:\r\n\r\n```ruby\r\nActiveSupport::Cache.lookup_store(:cascade_store,\r\n  :stores => [\r\n    [:memory_store, :size => 5.megabytes, :expires_in => 15.minutes],\r\n    [:mem_cache_store, 'localhost:11211'],\r\n  ]\r\n})\r\n```\r\n\r\nWhile this feature allows developers to chain arbitrary cache stores together, there is an extra cost to writing through to all caches, so it only makes sense to have a chain 2 or 3 deep.  Initially, I thought of allowing users to customize when and how deep they want to write through to the stores, but decided to keep it simple instead.\r\n", "_id": {"$oid": "52381a9abd3543c15100e338"}, "html_url": "https://github.com/rails/rails/pull/5263#issuecomment-4311441"}

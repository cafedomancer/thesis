{"issue_url": "https://api.github.com/repos/rails/rails/issues/201", "repo": "rails", "body": "Hi Andrew,\n\nThat's a pretty surprising result.  Here's a Postgres 8.4.4 query plan for the two forms against a 2 million row table running on my MacBook.  Note that the number of rows operated on in the sequential scan in the subquery form is shortcut after the LIMIT is reached.  Also the runtimes appear to strongly favor the subquery approach.  Obviously each database's query optimizer is different, but this is an operation that at least Postgres can optimize extremely well.  I believe Sqlite3 and MySQL can do the same, but will do more research.\n\nI definitely don't disagree that the count of the next page's records is easy to arrive at once you've either done a count of the unlimited query (which, as the example below shows can be quite expensive in and of itself), and min'd that against your page size.  Alternatively you can avoid hitting all the matching rows in the table if you use to_a and instantiate the whole next pageful of records (which could be moderately expensive if there are a number of branchy includes), but otherwise the present state of ActiveRecord doesn't allow you to get at what I see to be a very useful optimization provided by the database, while also not being semantically in line with the rest of ActiveRecord's aggregate calculations.\n\nCheers,\n-john\n\n    count_test=# select count(*) from stuff;\n      count  \n    ---------\n     2097152\n    (1 row)\n\n                                                          QUERY PLAN                                                       \n    -----------------------------------------------------------------------------------------------------------------------\n     Aggregate  (cost=50046.40..50046.41 rows=1 width=0) (actual time=623.414..623.414 rows=1 loops=1)\n       ->  Seq Scan on stuff  (cost=0.00..44803.52 rows=2097152 width=0) (actual time=0.017..391.077 rows=2097152 loops=1)\n     Total runtime: 623.484 ms\n    (3 rows)\n\n\n    count_test=# explain analyze select count(*) from (select 1 from stuff limit 100) as t;\n\n                                                          QUERY PLAN                                                       \n    -----------------------------------------------------------------------------------------------------------------------\n     Aggregate  (cost=3.39..3.40 rows=1 width=0) (actual time=0.054..0.054 rows=1 loops=1)\n       ->  Limit  (cost=0.00..2.14 rows=100 width=0) (actual time=0.010..0.046 rows=100 loops=1)\n             ->  Seq Scan on stuff  (cost=0.00..44803.52 rows=2097152 width=0) (actual time=0.009..0.024 rows=100 loops=1)\n     Total runtime: 0.078 ms\n    (4 rows)\n", "_id": {"$oid": "523865dcbd3543c151012747"}, "issue_id": 201, "url": "https://api.github.com/repos/rails/rails/issues/comments/863607", "html_url": "https://github.com/rails/rails/pull/201#issuecomment-863607", "updated_at": "2011-03-12T14:02:33Z", "user": {"subscriptions_url": "https://api.github.com/users/jmileham/subscriptions", "events_url": "https://api.github.com/users/jmileham/events{/privacy}", "repos_url": "https://api.github.com/users/jmileham/repos", "gists_url": "https://api.github.com/users/jmileham/gists{/gist_id}", "url": "https://api.github.com/users/jmileham", "login": "jmileham", "gravatar_id": "079ab1cc5aa71e625bb160e62b09f09c", "html_url": "https://github.com/jmileham", "following_url": "https://api.github.com/users/jmileham/following{/other_user}", "received_events_url": "https://api.github.com/users/jmileham/received_events", "organizations_url": "https://api.github.com/users/jmileham/orgs", "avatar_url": "https://1.gravatar.com/avatar/079ab1cc5aa71e625bb160e62b09f09c?d=https%3A%2F%2Fidenticons.github.com%2F02c1ffbf4378893da347eb8ec50b2456.png", "starred_url": "https://api.github.com/users/jmileham/starred{/owner}{/repo}", "id": 40619, "followers_url": "https://api.github.com/users/jmileham/followers", "type": "User"}, "created_at": "2011-03-12T14:01:55Z", "id": 863607, "owner": "rails"}
